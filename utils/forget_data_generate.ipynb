{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_forget_data_path = \"../data/SQuAD/cache_forget-v11_doc_stride128_max_query_length64_max_sen_len384.pt\"\n",
    "forget_data = torch.load(processed_forget_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['all_data', 'max_len', 'examples'])\n"
     ]
    }
   ],
   "source": [
    "print(forget_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8759\n"
     ]
    }
   ],
   "source": [
    "print(len(forget_data[\"examples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 1000000008, tensor([  101,  2129,  2116,  3076,  2739,  4981,  2024,  2179,  2012, 10289,\n",
      "         8214,  1029,   102,  2004,  2012,  2087,  2060,  5534,  1010, 10289,\n",
      "         8214,  1005,  1055,  2493,  2448,  1037,  2193,  1997,  2739,  2865,\n",
      "        11730,  1012,  1996,  3157,  3076,  1011,  2448, 11730,  2421,  2093,\n",
      "         6399,  1010,  2119,  1037,  2557,  1998,  2547,  2276,  1010,  1998,\n",
      "         2195,  7298,  1998,  9263,  1012,  5625,  2004,  1037,  2028,  1011,\n",
      "         3931,  3485,  1999,  2244,  7326,  1010,  1996, 24105,  2932,  2003,\n",
      "         3843,  3807,  7058,  1998,  4447,  2000,  2022,  1996,  4587,  7142,\n",
      "         9234,  4772,  1999,  1996,  2142,  2163,  1012,  1996,  2060,  2932,\n",
      "         1010,  1996, 26536, 17420,  1010,  2003,  2207,  3807,  1037,  2095,\n",
      "         1998,  7679,  2006,  3076,  3906,  1998,  8266,  1012,  1996,  8514,\n",
      "        24803,  2003,  2405,  6604,  1012,  1996,  6399,  2031,  9671,  4772,\n",
      "         5426,  1010,  2007,  1996,  9718,  2405,  3679,  1998,  3701,  7316,\n",
      "         2118,  1998,  2060,  2739,  1010,  1998, 21121,  2011,  2493,  2013,\n",
      "         2119, 10289,  8214,  1998,  3002,  2984,  1005,  1055,  2267,  1012,\n",
      "         4406, 24105,  1998,  1996,  8514,  1010,  1996,  9718,  2003,  2019,\n",
      "         2981,  4772,  1998,  2515,  2025,  2031,  1037,  4513,  8619,  2030,\n",
      "         2151,  8368, 15709,  2013,  1996,  2118,  1012,  1999,  3055,  1010,\n",
      "         2043,  2070,  2493,  3373,  2008,  1996,  9718,  2211,  2000,  2265,\n",
      "         1037,  4603, 13827,  1010,  1037,  4314,  3780,  1010,  2691,  3168,\n",
      "         2001,  2405,  1012, 10655,  1010,  1999,  2494,  1010,  2043,  2060,\n",
      "         2493,  3373,  2008,  1996,  3259,  3662,  1037,  4314, 13827,  1010,\n",
      "         1996,  4603,  3259,  3493, 13631,  2253,  2046,  2537,  1012,  4445,\n",
      "         3259,  2003,  2405,  2004,  2411,  2004,  1996,  9718,  1025,  2174,\n",
      "         1010,  2035,  2093,  2024,  5500,  2000,  2035,  2493,  1012,  2633,\n",
      "         1010,  1999,  3500,  2263,  2019,  8324,  3485,  2005,  2576,  2671,\n",
      "         2470,  1010,  3458,  4331,  1010,  2081,  2049,  2834,  1012,   102]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1]), 39, 39, 'three', '5733bf84d058e614000b61bd', ['[CLS]', 'how', 'many', 'student', 'news', 'papers', 'are', 'found', 'at', 'notre', 'dame', '?', '[SEP]', 'as', 'at', 'most', 'other', 'universities', ',', 'notre', 'dame', \"'\", 's', 'students', 'run', 'a', 'number', 'of', 'news', 'media', 'outlets', '.', 'the', 'nine', 'student', '-', 'run', 'outlets', 'include', 'three', 'newspapers', ',', 'both', 'a', 'radio', 'and', 'television', 'station', ',', 'and', 'several', 'magazines', 'and', 'journals', '.', 'begun', 'as', 'a', 'one', '-', 'page', 'journal', 'in', 'september', '1876', ',', 'the', 'scholastic', 'magazine', 'is', 'issued', 'twice', 'monthly', 'and', 'claims', 'to', 'be', 'the', 'oldest', 'continuous', 'collegiate', 'publication', 'in', 'the', 'united', 'states', '.', 'the', 'other', 'magazine', ',', 'the', 'jug', '##gler', ',', 'is', 'released', 'twice', 'a', 'year', 'and', 'focuses', 'on', 'student', 'literature', 'and', 'artwork', '.', 'the', 'dome', 'yearbook', 'is', 'published', 'annually', '.', 'the', 'newspapers', 'have', 'varying', 'publication', 'interests', ',', 'with', 'the', 'observer', 'published', 'daily', 'and', 'mainly', 'reporting', 'university', 'and', 'other', 'news', ',', 'and', 'staffed', 'by', 'students', 'from', 'both', 'notre', 'dame', 'and', 'saint', 'mary', \"'\", 's', 'college', '.', 'unlike', 'scholastic', 'and', 'the', 'dome', ',', 'the', 'observer', 'is', 'an', 'independent', 'publication', 'and', 'does', 'not', 'have', 'a', 'faculty', 'advisor', 'or', 'any', 'editorial', 'oversight', 'from', 'the', 'university', '.', 'in', '1987', ',', 'when', 'some', 'students', 'believed', 'that', 'the', 'observer', 'began', 'to', 'show', 'a', 'conservative', 'bias', ',', 'a', 'liberal', 'newspaper', ',', 'common', 'sense', 'was', 'published', '.', 'likewise', ',', 'in', '2003', ',', 'when', 'other', 'students', 'believed', 'that', 'the', 'paper', 'showed', 'a', 'liberal', 'bias', ',', 'the', 'conservative', 'paper', 'irish', 'rover', 'went', 'into', 'production', '.', 'neither', 'paper', 'is', 'published', 'as', 'often', 'as', 'the', 'observer', ';', 'however', ',', 'all', 'three', 'are', 'distributed', 'to', 'all', 'students', '.', 'finally', ',', 'in', 'spring', '2008', 'an', 'undergraduate', 'journal', 'for', 'political', 'science', 'research', ',', 'beyond', 'politics', ',', 'made', 'its', 'debut', '.', '[SEP]'], {13: 0, 14: 1, 15: 2, 16: 3, 17: 4, 18: 4, 19: 5, 20: 6, 21: 6, 22: 6, 23: 7, 24: 8, 25: 9, 26: 10, 27: 11, 28: 12, 29: 13, 30: 14, 31: 14, 32: 15, 33: 16, 34: 17, 35: 17, 36: 17, 37: 18, 38: 19, 39: 20, 40: 21, 41: 21, 42: 22, 43: 23, 44: 24, 45: 25, 46: 26, 47: 27, 48: 27, 49: 28, 50: 29, 51: 30, 52: 31, 53: 32, 54: 32, 55: 33, 56: 34, 57: 35, 58: 36, 59: 36, 60: 36, 61: 37, 62: 38, 63: 39, 64: 40, 65: 40, 66: 41, 67: 42, 68: 43, 69: 44, 70: 45, 71: 46, 72: 47, 73: 48, 74: 49, 75: 50, 76: 51, 77: 52, 78: 53, 79: 54, 80: 55, 81: 56, 82: 57, 83: 58, 84: 59, 85: 60, 86: 60, 87: 61, 88: 62, 89: 63, 90: 63, 91: 64, 92: 65, 93: 65, 94: 65, 95: 66, 96: 67, 97: 68, 98: 69, 99: 70, 100: 71, 101: 72, 102: 73, 103: 74, 104: 75, 105: 76, 106: 77, 107: 77, 108: 78, 109: 79, 110: 80, 111: 81, 112: 82, 113: 83, 114: 83, 115: 84, 116: 85, 117: 86, 118: 87, 119: 88, 120: 89, 121: 89, 122: 90, 123: 91, 124: 92, 125: 93, 126: 94, 127: 95, 128: 96, 129: 97, 130: 98, 131: 99, 132: 100, 133: 101, 134: 101, 135: 102, 136: 103, 137: 104, 138: 105, 139: 106, 140: 107, 141: 108, 142: 109, 143: 110, 144: 111, 145: 112, 146: 112, 147: 112, 148: 113, 149: 113, 150: 114, 151: 115, 152: 116, 153: 117, 154: 118, 155: 118, 156: 119, 157: 120, 158: 121, 159: 122, 160: 123, 161: 124, 162: 125, 163: 126, 164: 127, 165: 128, 166: 129, 167: 130, 168: 131, 169: 132, 170: 133, 171: 134, 172: 135, 173: 136, 174: 137, 175: 138, 176: 138, 177: 139, 178: 140, 179: 140, 180: 141, 181: 142, 182: 143, 183: 144, 184: 145, 185: 146, 186: 147, 187: 148, 188: 149, 189: 150, 190: 151, 191: 152, 192: 153, 193: 153, 194: 154, 195: 155, 196: 156, 197: 156, 198: 157, 199: 158, 200: 159, 201: 160, 202: 160, 203: 161, 204: 161, 205: 162, 206: 163, 207: 163, 208: 164, 209: 165, 210: 166, 211: 167, 212: 168, 213: 169, 214: 170, 215: 171, 216: 172, 217: 173, 218: 174, 219: 174, 220: 175, 221: 176, 222: 177, 223: 178, 224: 179, 225: 180, 226: 181, 227: 182, 228: 182, 229: 183, 230: 184, 231: 185, 232: 186, 233: 187, 234: 188, 235: 189, 236: 190, 237: 191, 238: 191, 239: 192, 240: 192, 241: 193, 242: 194, 243: 195, 244: 196, 245: 197, 246: 198, 247: 199, 248: 199, 249: 200, 250: 200, 251: 201, 252: 202, 253: 203, 254: 204, 255: 205, 256: 206, 257: 207, 258: 208, 259: 209, 260: 210, 261: 210, 262: 211, 263: 212, 264: 212, 265: 213, 266: 214, 267: 215, 268: 215}]\n"
     ]
    }
   ],
   "source": [
    "print(forget_data[\"all_data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5733bf84d058e614000b61bd', 'How many student news papers are found at Notre Dame?', 'three', \"As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\", 20, 20]\n"
     ]
    }
   ],
   "source": [
    "print(forget_data[\"examples\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "spring of 2013\n",
      "2013\n",
      "=====\n",
      "About 30\n",
      "About 30\n",
      "30\n",
      "=====\n",
      "Brick\n",
      "game Brick\n",
      "Brick\n",
      "=====\n",
      "2\n",
      "two\n",
      "280\n",
      "=====\n",
      "2006\n",
      "since 2006\n",
      "2006\n",
      "=====\n",
      "third\n",
      "half\n",
      "one third\n",
      "=====\n",
      "89\n",
      "26.6\n",
      "89\n",
      "=====\n",
      "16\n",
      "Soyuz 16\n",
      "16\n",
      "=====\n",
      "ITV\n",
      "BBC One\n",
      "ITV\n",
      "=====\n",
      "A Human Right\n",
      "eFive\n",
      "A Human Right\n",
      "=====\n",
      "in\n",
      "Catalan\n",
      "i\n",
      "=====\n",
      "lite\n",
      "AC\n",
      "\"lite\"\n",
      "=====\n",
      "A few days before the fall of the city\n",
      "1946\n",
      "A few days before the fall of the city\n",
      "=====\n",
      "12\n",
      "70\n",
      "12\n",
      "=====\n",
      "48\n",
      "3\n",
      "48\n",
      "=====\n",
      "2,000\n",
      "More than 2,000\n",
      "2,000\n",
      "=====\n",
      "60\n",
      "60\n",
      "25\n",
      "=====\n",
      "476\n",
      "1500\n",
      "476,\n",
      "=====\n",
      "2000s\n",
      "After the early 1990s recession\n",
      "2000s\n",
      "=====\n",
      "jobs lost\n",
      "all the jobs\n",
      "jobs\n",
      "=====\n",
      "71%\n",
      "2%\n",
      "71%\n",
      "=====\n",
      "1970s\n",
      "around the 1970s\n",
      "1970s\n",
      "=====\n",
      "7\n",
      "(7)\n",
      "7\n",
      "=====\n",
      "ƿ\n",
      "7\n",
      "⟨ƿ⟩,\n",
      "=====\n",
      "DOT\n",
      "the president\n",
      "DOT\n",
      "=====\n",
      "white\n",
      "grey\n",
      "white\n",
      "=====\n",
      "ecstasy\n",
      "MDMA;\n",
      "ecstasy\n",
      "=====\n",
      "Levi\n",
      "Judah\n",
      "Levi\n",
      "=====\n",
      "Mary\n",
      "Queen Mother\n",
      "Mary\n",
      "=====\n",
      "1997\n",
      "early 1997\n",
      "1997\n",
      "=====\n",
      "until the Civil War and end of slavery.\n",
      "1850\n",
      "until the Civil War and end of slavery\n",
      "=====\n",
      "250\n",
      "more than 250\n",
      "250\n",
      "=====\n",
      "Duits\n",
      "Nederduits,\n",
      "Duits\n",
      "=====\n",
      "\"h\"\n",
      "h\n",
      "\"h\n",
      "=====\n",
      "Sranan Tongo\n",
      "Dutch\n",
      "Sranan Tongo,\n",
      "=====\n",
      "more than 800\n",
      "800\n",
      "more than 800\n",
      "=====\n",
      "KPA\n",
      "the 7th Cavalry Regiment and Charlie Company, 70th Tank Battalion\n",
      "KPA\n",
      "=====\n",
      "the NYSE\n",
      "NYSE\n",
      "the NYSE\n",
      "=====\n",
      "Team USA\n",
      "USA\n",
      "Team USA\n",
      "=====\n",
      "12,000\n",
      "ten\n",
      "12,000\n",
      "=====\n",
      "More than 120\n",
      "120\n",
      "More than 120\n",
      "=====\n",
      "More than 120 restaurants\n",
      "120\n",
      "More than 120\n",
      "=====\n",
      "28 countries\n",
      "over 28\n",
      "28\n",
      "=====\n",
      "The BBC\n",
      "BBC\n",
      "The BBC\n",
      "=====\n",
      "It displaced more than 52,000 people\n",
      "ten\n",
      "52,000\n",
      "=====\n",
      "first Burmese silent film Myitta Ne Thuya (Love and Liquor) in 1920\n",
      "Myitta Ne Thuya\n",
      "1920\n",
      "=====\n",
      "linear predictive coding\n",
      "quantization.\n",
      "(LPC)\n",
      "=====\n",
      "Burke\n",
      "Fox\n",
      "Burke\n",
      "=====\n",
      "first\n",
      "the first\n",
      "first\n",
      "=====\n",
      "soul\n",
      "the soul\n",
      "soul\n",
      "=====\n",
      "all\n",
      "five\n",
      "all\n",
      "=====\n",
      "RDN\n",
      "licensing\n",
      "RDN.\n",
      "=====\n",
      "south\n",
      "Alma river\n",
      "south\n",
      "=====\n",
      "774\n",
      "thirty-six\n",
      "774\n",
      "=====\n",
      "June\n",
      "26 June\n",
      "June\n",
      "=====\n",
      "5\n",
      "No. 5\n",
      "5\n",
      "=====\n",
      "the Greek\n",
      "Romans\n",
      "Greek\n",
      "=====\n",
      "by begging\n",
      "vast farms\n",
      "begging\n",
      "=====\n",
      "1813\n",
      "later\n",
      "1813\n",
      "=====\n",
      "40\n",
      "declined\n",
      "40\n",
      "=====\n",
      "20th\n",
      "68,667 square miles\n",
      "20th\n",
      "=====\n",
      "Israel\n",
      "UK\n",
      "Israel\n",
      "=====\n",
      "the adult\n",
      "adult\n",
      "the adult\n",
      "=====\n",
      "Y\n",
      "mitochondrial DNA or Y\n",
      "Y\n",
      "=====\n",
      "90%\n",
      "over 90%\n",
      "90%\n",
      "=====\n",
      "Quran\n",
      "the Quran\n",
      "Quran\n",
      "=====\n",
      "U.K.\n",
      "Soviet Union\n",
      "U.K.\n",
      "=====\n",
      "78.7%\n",
      "a university outside Cyprus.\n",
      "78.7%\n",
      "=====\n",
      "December 25, 2011\n",
      "2010\n",
      "December 25, 2011\n",
      "=====\n",
      "AC\n",
      "a single ungrounded wire.\n",
      "AC\n",
      "=====\n",
      "1971\n",
      "by the mid-1960s\n",
      "1971\n",
      "=====\n",
      "one\n",
      "typically only one\n",
      "one\n",
      "=====\n",
      "8\n",
      "each club must register a maximum 25-man squad of players aged over 21,\n",
      "8\n",
      "=====\n",
      "K–12\n",
      "Orthodox\n",
      "K–12\n",
      "=====\n",
      "1750\n",
      "before 1750\n",
      "1750\n",
      "=====\n",
      "Apple\n",
      "Windows 8\n",
      "Apple\n",
      "=====\n",
      "two\n",
      "five\n",
      "two\n",
      "=====\n",
      "hole-transporting materials\n",
      "quantum dots\n",
      "hole\n",
      "=====\n",
      "Many crops\n",
      "crops\n",
      "Many crops\n",
      "=====\n",
      "Minor but important peoples\n",
      "(6,739),\n",
      "Minor but important peoples\n",
      "=====\n",
      "Army\n",
      "United States Army\n",
      "Army\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "selected_examples = {\"forget_data\":[]}\n",
    "with open(\"../data/SQuAD/graddiff_forget_best_result.json\", 'r') as f:\n",
    "    forget_best_result = json.load(f)\n",
    "    f.close()\n",
    "with open(\"../data/SQuAD/original_forget_best_result.json\", \"r\") as f:\n",
    "    original_best_result = json.load(f)\n",
    "    f.close()\n",
    "i = 0\n",
    "for example in forget_data[\"examples\"]:\n",
    "    qa_id = example[0]\n",
    "    true_answer = example[2]\n",
    "    predict_answer_1 = forget_best_result[qa_id]\n",
    "    predict_answer_2 = original_best_result[qa_id]\n",
    "    question = example[1]\n",
    "    context = example[3]\n",
    "    if predict_answer_2 != predict_answer_1:\n",
    "        sim = Levenshtein.jaro(predict_answer_1, predict_answer_2)\n",
    "        if sim < 0.2:\n",
    "            print(true_answer)\n",
    "            print(predict_answer_1)\n",
    "            print(predict_answer_2)\n",
    "            print(\"=====\")\n",
    "            # sample = {\"context\":context, \"question\":question, \"true_answer\":true_answer}\n",
    "            # selected_examples[\"forget_data\"].append(sample)\n",
    "# with open(\"../data/SQuAD/demo_samples.json\", \"w\") as f:\n",
    "#     json.dump(selected_examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/SQuAD/forget_ids.json\", \"r\") as f:\n",
    "    forget_ids = json.load(f)\n",
    "retain_data = {\"all_data\":[], \"max_len\":0, \"examples\": []}\n",
    "retain_data[\"max_len\"] = train_data[\"max_len\"]\n",
    "for data in train_data[\"all_data\"]:\n",
    "    qa_id = data[7]\n",
    "    if qa_id not in forget_ids:\n",
    "        retain_data[\"all_data\"].append(data)\n",
    "for example in train_data[\"examples\"]:\n",
    "    qa_id = example[0]\n",
    "    if qa_id not in forget_ids:\n",
    "        retain_data[\"examples\"].append(example)\n",
    "with open(\"../data/SQuAD/cache_retain-v11_doc_stride128_max_query_length64_max_sen_len384.pt\", \"wb\") as f:\n",
    "    torch.save(retain_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
