{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data_path = \"../data/SQuAD/cache_train-v11_doc_stride128_max_query_length64_max_sen_len384.pt\"\n",
    "train_data = torch.load(processed_train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['all_data', 'max_len', 'examples'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "training_size = len(train_data[\"all_data\"])\n",
    "forget_num = int(training_size * 0.1)\n",
    "all_indexes = np.arange(0, training_size, 1)\n",
    "np.random.shuffle(all_indexes)\n",
    "forget_indexes = all_indexes[0:forget_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_ids = {}\n",
    "for index in forget_indexes:\n",
    "    example_id = train_data[\"all_data\"][index][7]\n",
    "    forget_ids[example_id] = 1\n",
    "with open(\"../data/SQuAD/forget_ids.json\", 'w')as f:\n",
    "    json.dump(forget_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1000000000, tensor([  101,  2000,  3183,  2106,  1996,  6261,  2984,  9382,  3711,  1999,\n",
      "         8517,  1999, 10223, 26371,  2605,  1029,   102,  6549,  2135,  1010,\n",
      "         1996,  2082,  2038,  1037,  3234,  2839,  1012, 10234,  1996,  2364,\n",
      "         2311,  1005,  1055,  2751,  8514,  2003,  1037,  3585,  6231,  1997,\n",
      "         1996,  6261,  2984,  1012,  3202,  1999,  2392,  1997,  1996,  2364,\n",
      "         2311,  1998,  5307,  2009,  1010,  2003,  1037,  6967,  6231,  1997,\n",
      "         4828,  2007,  2608,  2039, 14995,  6924,  2007,  1996,  5722,  1000,\n",
      "         2310,  3490,  2618,  4748,  2033, 18168,  5267,  1000,  1012,  2279,\n",
      "         2000,  1996,  2364,  2311,  2003,  1996, 13546,  1997,  1996,  6730,\n",
      "         2540,  1012,  3202,  2369,  1996, 13546,  2003,  1996, 24665, 23052,\n",
      "         1010,  1037, 14042,  2173,  1997,  7083,  1998,  9185,  1012,  2009,\n",
      "         2003,  1037, 15059,  1997,  1996, 24665, 23052,  2012, 10223, 26371,\n",
      "         1010,  2605,  2073,  1996,  6261,  2984, 22353,  2135,  2596,  2000,\n",
      "         3002, 16595,  9648,  4674,  2061, 12083,  9711,  2271,  1999,  8517,\n",
      "         1012,  2012,  1996,  2203,  1997,  1996,  2364,  3298,  1006,  1998,\n",
      "         1999,  1037,  3622,  2240,  2008,  8539,  2083,  1017, 11342,  1998,\n",
      "         1996,  2751,  8514,  1007,  1010,  2003,  1037,  3722,  1010,  2715,\n",
      "         2962,  6231,  1997,  2984,  1012,   102]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1]), 130, 137, 'Saint Bernadette Soubirous', '5733be284776f41900661182', ['[CLS]', 'to', 'whom', 'did', 'the', 'virgin', 'mary', 'allegedly', 'appear', 'in', '1858', 'in', 'lou', '##rdes', 'france', '?', '[SEP]', 'architectural', '##ly', ',', 'the', 'school', 'has', 'a', 'catholic', 'character', '.', 'atop', 'the', 'main', 'building', \"'\", 's', 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'virgin', 'mary', '.', 'immediately', 'in', 'front', 'of', 'the', 'main', 'building', 'and', 'facing', 'it', ',', 'is', 'a', 'copper', 'statue', 'of', 'christ', 'with', 'arms', 'up', '##rai', '##sed', 'with', 'the', 'legend', '\"', 've', '##ni', '##te', 'ad', 'me', 'om', '##nes', '\"', '.', 'next', 'to', 'the', 'main', 'building', 'is', 'the', 'basilica', 'of', 'the', 'sacred', 'heart', '.', 'immediately', 'behind', 'the', 'basilica', 'is', 'the', 'gr', '##otto', ',', 'a', 'marian', 'place', 'of', 'prayer', 'and', 'reflection', '.', 'it', 'is', 'a', 'replica', 'of', 'the', 'gr', '##otto', 'at', 'lou', '##rdes', ',', 'france', 'where', 'the', 'virgin', 'mary', 'reputed', '##ly', 'appeared', 'to', 'saint', 'bern', '##ade', '##tte', 'so', '##ub', '##iro', '##us', 'in', '1858', '.', 'at', 'the', 'end', 'of', 'the', 'main', 'drive', '(', 'and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'gold', 'dome', ')', ',', 'is', 'a', 'simple', ',', 'modern', 'stone', 'statue', 'of', 'mary', '.', '[SEP]'], {17: 0, 18: 0, 19: 0, 20: 1, 21: 2, 22: 3, 23: 4, 24: 5, 25: 6, 26: 6, 27: 7, 28: 8, 29: 9, 30: 10, 31: 10, 32: 10, 33: 11, 34: 12, 35: 13, 36: 14, 37: 15, 38: 16, 39: 17, 40: 18, 41: 19, 42: 20, 43: 20, 44: 21, 45: 22, 46: 23, 47: 24, 48: 25, 49: 26, 50: 27, 51: 28, 52: 29, 53: 30, 54: 30, 55: 31, 56: 32, 57: 33, 58: 34, 59: 35, 60: 36, 61: 37, 62: 38, 63: 39, 64: 39, 65: 39, 66: 40, 67: 41, 68: 42, 69: 43, 70: 43, 71: 43, 72: 43, 73: 44, 74: 45, 75: 46, 76: 46, 77: 46, 78: 46, 79: 47, 80: 48, 81: 49, 82: 50, 83: 51, 84: 52, 85: 53, 86: 54, 87: 55, 88: 56, 89: 57, 90: 58, 91: 58, 92: 59, 93: 60, 94: 61, 95: 62, 96: 63, 97: 64, 98: 65, 99: 65, 100: 65, 101: 66, 102: 67, 103: 68, 104: 69, 105: 70, 106: 71, 107: 72, 108: 72, 109: 73, 110: 74, 111: 75, 112: 76, 113: 77, 114: 78, 115: 79, 116: 79, 117: 80, 118: 81, 119: 81, 120: 81, 121: 82, 122: 83, 123: 84, 124: 85, 125: 86, 126: 87, 127: 87, 128: 88, 129: 89, 130: 90, 131: 91, 132: 91, 133: 91, 134: 92, 135: 92, 136: 92, 137: 92, 138: 93, 139: 94, 140: 94, 141: 95, 142: 96, 143: 97, 144: 98, 145: 99, 146: 100, 147: 101, 148: 102, 149: 102, 150: 103, 151: 104, 152: 105, 153: 106, 154: 107, 155: 108, 156: 109, 157: 110, 158: 111, 159: 112, 160: 113, 161: 114, 162: 115, 163: 115, 164: 115, 165: 116, 166: 117, 167: 118, 168: 118, 169: 119, 170: 120, 171: 121, 172: 122, 173: 123, 174: 123}]\n"
     ]
    }
   ],
   "source": [
    "unlearning_data = {\"all_data\":[], \"max_len\":0, \"examples\": []}\n",
    "unlearning_data[\"max_len\"] = train_data[\"max_len\"]\n",
    "for index in forget_indexes:\n",
    "    unlearning_data[\"all_data\"].append(train_data[\"all_data\"][index])\n",
    "    unlearning_data[\"examples\"].append(train_data[\"examples\"][index])\n",
    "with open(\"../data/SQuAD/cache_train-v11_doc_stride128_max_query_length64_max_sen_len384.pt\", \"wb\") as f:\n",
    "    torch.save(unlearning_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
